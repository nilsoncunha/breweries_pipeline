# Breweries Pipeline

Este projeto implementa um pipeline de dados com arquitetura **Medallion (Bronze, Silver, Gold)** 
utilizando **Apache Spark com Delta Lake**, **MinIO como data lake local (S3 compatÃ­vel)** e **Apache Airflow** como 
orquestrador. Os dados sÃ£o extraÃ­dos da API pÃºblica [Open Brewery DB](https://www.openbrewerydb.org/), transformados, 
particionados e agregados, prontos para anÃ¡lise.

---

## ğŸ”§ Tecnologias Utilizadas

- ğŸ Python 3.10
- âš™ï¸ Apache Spark 3.5.3 + Delta Lake 3.3.1
- â˜ï¸ MinIO (S3 compatÃ­vel)
- ğŸŒ¬ï¸ Apache Airflow 2.8 com PostgreSQL
- ğŸ˜ PostgreSQL 13
- ğŸ³ Docker e Docker Compose

---

## ğŸ§© VersÃµes e Compatibilidade

| Componente       | VersÃ£o Utilizada  | ObservaÃ§Ãµes                                                                         |
|------------------|-------------------|-------------------------------------------------------------------------------------|
| **Apache Spark** | `3.5.3`           | Engine de processamento principal                                                   |
| **Scala**        | `2.12`            | Requisito de compatibilidade do Delta Lake                                          |
| **Delta Lake**   | `3.3.1`           | CompatÃ­vel com Spark 3.5.3 (JARs: `delta-spark`, `delta-storage`, `delta-contribs`) |
| **Hadoop AWS**   | `3.3.5`           | Suporte ao `s3a://` com MinIO                                                       |
| **AWS SDK**      | `2.20.158`        | RequisiÃ§Ã£o de objetos via boto3/spark                                               |
| **Airflow**      | `2.8.1`           | Com `LocalExecutor` e PostgreSQL                                                    |
| **PostgreSQL**   | `13`              | Backend do Airflow                                                                  |
| **MinIO**        | `latest`          | Buckets criados automaticamente via `mc`                                            |

---

### ğŸ“ JARs utilizados

```Dockerfile
# Delta Lake
ADD https://repo1.maven.org/maven2/io/delta/delta-spark_2.12/3.3.1/delta-spark_2.12-3.3.1.jar .
ADD https://repo1.maven.org/maven2/io/delta/delta-contribs_2.12/3.3.1/delta-contribs_2.12-3.3.1.jar .
ADD https://repo1.maven.org/maven2/io/delta/delta-storage/3.3.1/delta-storage-3.3.1.jar .

# ConexÃ£o com MinIO
ADD https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-aws/3.3.5/hadoop-aws-3.3.5.jar .
ADD https://repo1.maven.org/maven2/software/amazon/awssdk/bundle/2.20.158/bundle-2.20.158.jar .
```

---

## ğŸ“š Arquitetura Medallion

- **Bronze**: Dados crus da API (1 arquivo por pÃ¡gina), salvos no bucket `bronze` no formato JSON.
- **Silver**: TransformaÃ§Ã£o e limpeza, salvos em Delta Lake particionado por `state`, no bucket `silver`.
- **Gold**: AgregaÃ§Ã£o da contagem de cervejarias por `state` e `brewery_type`, tambÃ©m em Delta, no bucket `gold`.

---

## âš™ï¸ ParametrizaÃ§Ã£o com YAML

Aqui trouxe uma opÃ§Ã£o para deixar mais genÃ©rico o cÃ³digo e quando necessÃ¡rio realizar a alteraÃ§Ã£o apenas no YAML
caso fosse necessÃ¡rio modificar o nome das pastas, quantidade por pÃ¡ginas ou o nome do arquivo.

---

## ğŸš€ Como Executar o Projeto

1. Clone o repositÃ³rio
```bash
git clone https://github.com/nilsoncunha/breweries_pipeline.git
cd breweries_pipeline
```

2. O comando abaixo irÃ¡ subir os containers com todos os serviÃ§os necessÃ¡rios para a execuÃ§Ã£o do projeto. Inclusive a criaÃ§Ã£o dos buckets no `MinIO`
**_Obs: Antes de executar o comando abaixo, verifique se hÃ¡ containers ativos nas portas necessÃ¡rias para esse projeto_**

| ServiÃ§o       | Porta        |
|---------------|--------------|
| **minio**     | 9000 / 9001  |
| **postgres**  | 5432         |
| **airflow**   | 8080         |

```bash
docker-compose up -d --build
```

3. Quando finalizado, vocÃª conseguirÃ¡ acessar o `Airflow` e o `MinIO` atravÃ©s dos links abaixo.

| Sistema           | URL                    | Credenciais      |
|-------------------|------------------------|------------------|
| **Airflow**       | http://localhost:8080  | admin / admin    |
| **MinIO Console** | http://localhost:9001  | minio / minio123 |

4. Ao acessar o `Airflow` habilite a dag e clique para realizar o `Trigger Dag`. O nÃºmero de pÃ¡ginas jÃ¡ estÃ¡ configurado nos parÃ¢metros.
Aqui quis demonstrar que poderÃ­amos deixar um parÃ¢metro para pegar a partir de uma pÃ¡gina especÃ­fica e facilitar futuramente um reprocessamento.
O cÃ³digo nÃ£o estÃ¡ adaptado para pegar apenas uma pÃ¡gina, mas sim do nÃºmero da pÃ¡gina informada atÃ© a API retornar vazia.

5. Ao realizar a `Trigger Dag` o processo durou cerca de `3 minutos` para completar.
 
## ğŸ—‚ï¸ Estrutura do Projeto

```markdown
â”œâ”€â”€ airflow/
â”‚   â””â”€â”€ dags/
â”‚       â””â”€â”€ breweries_dag.py           # DAG do Airflow com tasks bronze/silver/gold
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ to_bronze.py                   # ExtraÃ§Ã£o paginada da API + upload pro MinIO
â”‚   â”œâ”€â”€ to_silver.py                   # Limpeza + Delta partitioned by state
â”‚   â”œâ”€â”€ to_gold.py                     # AgregaÃ§Ã£o Delta
â”‚   |â”€â”€ utils.py
|   |â”€â”€ utils_config.yml               # ConfiguraÃ§Ãµes do pipeline
â”œâ”€â”€ .gitignore
â”œâ”€â”€ docker-compose.yaml
â”‚â”€â”€ Dockerfile                         # Spark + Delta configurado
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

## ğŸ›¡ï¸ Monitoramento e Alertas - NÃ£o implementada

Nesse caso poderia utilizar o `retries` e `retry_delay` (estÃ£o comentados no cÃ³digo) para em caso de falha rodar a task novamente.
Outro ponto seria a inclusÃ£o de alertas sendo enviado para o e-mail ou Slack para notificar as falhas e com isso 
analisarmos os logs que foram gerados pelo Airflow.
